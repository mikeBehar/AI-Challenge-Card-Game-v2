# Lessons Learned: Case Study Design & Implementation

**Purpose**: Capture insights from actual student deliberations to inform future case development and facilitation.

**Last Updated**: November 27, 2025  
**Source**: Case 1 Board Deliberation Transcript Analysis

---

## Overview

This document captures what we've learned from deploying Case 1 (Liberty Regional Bank AI Hiring Tool) with 17 adult learners in the "Generative AI for Business and Creative Professionals" course. These insights should directly inform the design of Cases 2-4 and future iterations of the course.

**Key Meta-Lesson**: The simulation format works! Students engaged authentically, wrestled with genuine trade-offs, and demonstrated sophisticated business thinking. We should build on this success while addressing identified gaps.

---

## Part 1: What Worked Exceptionally Well

### 1.1 The "Control Your Destiny" Principle Resonated Powerfully

**What Happened**:
Brad's argument about not relying on external vendors to fix critical problems landed with significant force. His "control your own destiny" framing became a recurring theme and influenced multiple participants' thinking.

**Why It Matters**:
- Students with 4-15+ years business experience have lived vendor disappointments
- Organizational autonomy is a deeply felt value for experienced professionals
- The vendor dependency angle added business realism that pure ethics discussions would miss

**Design Implications for Future Cases**:
- ✅ **Include explicit build-vs-buy decisions** in Cases 2-4
- ✅ **Add vendor reliability as a variable** (vendor promises vs. delivery track record)
- ✅ **Create options that contrast internal development vs. external solutions**
- ✅ **Include vendor relationship management as a business skill to assess**

**Example Application**:
Case 2 could present a choice between:
- Option A: Buy turnkey AI solution from established vendor (fast, expensive, less control)
- Option B: Build internal AI capability (slow, cheaper long-term, full control)
- Option C: Hybrid approach (start with vendor, transition to internal)

---

### 1.2 Real-World Experience Enhanced Discussion Quality

**What Happened**:
Ed's story about his wife's mortgage industry experience and the 2008 crisis added tremendous credibility and emotional weight to his arguments. His willingness to share personal experience enriched the entire deliberation.

**Why It Matters**:
- Students are NOT typical college students - they're experienced professionals
- Their 4-15+ years in business is an untapped pedagogical asset
- Personal stories create "teachable moments" more effectively than abstract principles
- Experience-based arguments are more persuasive to peers than theoretical ones

**Design Implications for Future Cases**:
- ✅ **Add pre-meeting question**: "Describe a similar decision you've faced in your career"
- ✅ **Budget time for experience sharing** during deliberations (5-10 minutes)
- ✅ **Create cases that explicitly invite analogies** to common business situations
- ✅ **Value experiential knowledge in rubric** (not just analytical sophistication)

**Example Application**:
Pre-meeting Question 5 for all future cases:
> "Professional Experience Connection (5 points): In your 4-15+ years of work experience, describe a situation where you or your organization faced a similar decision. What happened? What did you learn? How does that experience inform your thinking on this case?"

---

### 1.3 Students Are Ready for Greater Complexity

**What Happened**:
The quality of deliberation far exceeded expectations. Students:
- Wrestled with genuine ambiguity (no "right answer" seeking)
- Balanced multiple competing values simultaneously
- Asked sophisticated questions (Dan's "human bias baseline" question)
- Changed positions based on arguments (Ed's vote shift)
- Maintained professional discourse under disagreement

**Why It Matters**:
- We may have underestimated their analytical capacity
- They can handle more financial modeling, more stakeholders, more moving parts
- The 5-option structure worked well - didn't overwhelm them
- They're hungry for realism, not simplified scenarios

**Design Implications for Future Cases**:
- ✅ **Increase case complexity progressively** (Case 4 should be most complex)
- ✅ **Provide analytical tools** (financial templates, decision matrices)
- ✅ **Include mid-case information reveals** ("just got this email from...")
- ✅ **Add time pressure elements** (decisions need to be made quickly)
- ✅ **Create more stakeholder voices** (customer testimonials, employee perspectives)

**Example Application**:
Case 3 could include:
- Initial case materials (standard)
- PLUS: "Breaking News" email revealed 30 minutes into deliberation
- PLUS: Financial model spreadsheet they must complete
- PLUS: Competing stakeholder testimonial videos (2 minutes each)

---

### 1.4 The Board Simulation Format Drives Authentic Engagement

**What Happened**:
Framing students as "Board of Directors" created genuine ownership. They took their responsibilities seriously, prepared thoroughly, and engaged as peers (not students waiting to be told the "right answer").

**Why It Matters**:
- Adult learners respond to respect and responsibility
- Peer-to-peer deliberation > instructor-led discussion
- The voting mechanism created stakes (consequences matter)
- Role-based framing activated professional identities

**Design Implications for Future Cases**:
- ✅ **Maintain board framing** for all cases
- ✅ **Add specific board member roles** in some cases (CFO, COO, board chair, etc.)
- ✅ **Create fiduciary duty reminders** in case materials
- ✅ **Include board process elements** (motions, seconds, amendments)
- ✅ **Reference board governance best practices**

**Example Application**:
Case 4 could assign specific board roles:
- Board Chair (must facilitate discussion)
- CFO (must present financial analysis)
- Chief Risk Officer (must present risk assessment)
- Independent Director (must challenge groupthink)
- Employee Representative (must voice workforce concerns)

---

### 1.5 Respectful Disagreement Created Learning Opportunities

**What Happened**:
Multiple viewpoints coexisted without personal attacks. Students disagreed professionally, listened to each other, and in at least one case (Ed) changed their minds based on arguments heard.

**Why It Matters**:
- This is the highest form of learning - genuine intellectual exchange
- Ed's vote change demonstrates deliberation working as intended
- Professional discourse is itself a valuable business skill
- Diversity of perspectives enriched everyone's thinking

**Design Implications for Future Cases**:
- ✅ **Explicitly reward "changing your mind"** in rubric
- ✅ **Create post-deliberation reflection**: "What argument most challenged your thinking?"
- ✅ **Acknowledge vote changes publicly** (celebrate intellectual humility)
- ✅ **Build in "steel man" exercise** (argue for position you disagree with)

**Example Application**:
Add to rubric:
> "Intellectual Humility Bonus (+2 points): Student demonstrates willingness to genuinely consider opposing views, acknowledges limitations of their position, or changes their vote based on deliberation. Evidence: explicit statement in post-meeting reflection or documented vote change."

---

## Part 2: What Students Struggled With or Missed

### 2.1 Limited Engagement with Specific Case Data (Via AI Assistance)

**What Happened**:
Few students referenced the most damning statistic: **23% auto-decline rate for Black applicants vs. 12% for white applicants**. Many arguments stayed at general level rather than engaging with case specifics. More importantly, there was little evidence of students using AI tools to help them understand and interpret the case data.

**Why It Matters**:
- The numbers tell a powerful story they didn't fully leverage
- General principles are good; AI-assisted specific analysis is better
- Business decisions require understanding actual data - and AI can help with that
- Students need practice using AI to explain complex information
- This is a course about AI partnership, not financial analysis skills

**Design Implications for Future Cases**:
- ✅ **Require AI-assisted quantitative understanding** in pre-meeting assignments
- ✅ **Teach effective prompting for data interpretation** (not calculation skills)
- ✅ **Ask students to show prompts that helped them understand the numbers**
- ✅ **Include "AI-assisted analysis" explicitly in rubric**
- ✅ **Provide examples of good vs. weak prompts for financial/data questions**
- ✅ **Focus on prompt sophistication, not finance expertise**

**Example Application**:
Pre-meeting Assignment Question 2 format:
> "AI-Assisted Financial Analysis (10 points): 
> 
> Use an AI assistant (ChatGPT, Claude, Gemini, etc.) to help you understand the financial implications of each option.
> 
> Submit:
> 1. **Two prompts you used** to get financial clarity (show your actual prompts)
> 2. **What you learned** from the AI's analysis (2-3 sentences per prompt)
> 3. **Your synthesis**: Based on the AI's help, which option makes the most financial sense? Why? (150 words)
> 4. **Critical evaluation**: Did the AI miss anything important? What would you probe deeper on? (100 words)
> 
> **Strong prompts ask AI to**:
> - Explain complex concepts in plain language
> - Compare options across multiple dimensions
> - Identify hidden costs or risks
> - Challenge optimistic projections
> - Surface assumptions that matter
> 
> **Weak prompts**:
> - 'What should I do?' (asks AI to decide)
> - 'Which is cheapest?' (too vague)
> - Just summarizing case content"

**Critical Insight**: 
This is NOT a finance course. Students don't need to calculate NPV themselves. They need to learn how to USE AI to help them understand financial implications and make informed business recommendations. The skill is in asking the right questions and critically evaluating AI's answers.

---

### 2.2 Minimal Inter-Participant Dialogue

**What Happened**:
Most comments were directed to the instructor rather than to each other. Limited direct engagement with others' arguments. More "here's my view" than "I disagree with Jorge because..."

**Why It Matters**:
- Peer-to-peer learning is more powerful than instructor-student
- Real board meetings involve direct debate, not serial monologues
- They're missing opportunity to practice professional disagreement
- Instructor becomes bottleneck rather than facilitator

**Design Implications for Future Cases**:
- ✅ **Structure explicit debate time** ("Brad and Dee, you disagree - 3 minutes each")
- ✅ **Require responses to specific arguments** in written assignments
- ✅ **Use discussion forum pre-meeting** for asynchronous debate
- ✅ **Facilitate less, orchestrate more** (connect participants to each other)
- ✅ **Create "response rounds"** (everyone must respond to one prior comment)

**Example Application**:
Meeting Structure Revision:
- Minutes 0-30: Opening statements (2 min each, randomized order)
- Minutes 30-60: **Direct debate rounds** (facilitator pairs opponents)
- Minutes 60-90: Open deliberation
- Minutes 90-120: Closing arguments + vote

**Facilitation Language**:
"Brad, you just argued X. Dee, you said Y, which seems to contradict Brad's point. Dee, respond directly to Brad's argument. Then Brad, you'll have 2 minutes to respond."

---

### 2.3 Limited Explicit AI Tool Usage During Deliberation

**What Happened**:
Almost no references to "I just asked Claude..." or "ChatGPT suggested..." during the live discussion. The AI consultation was happening pre-meeting (in assignments) but not during deliberation.

**Why It Matters**:
- Course is "Generative AI for Business and Creative Professionals"
- A key goal is "advanced prompting techniques"
- Real business use = consulting AI in real-time during decisions
- Missing opportunity to assess prompt quality in context

**Design Implications for Future Cases**:
- ✅ **Build in mandatory AI consultation break** mid-deliberation
- ✅ **Require sharing prompts and results** in real-time
- ✅ **Create "AI consultation log"** in Google Form
- ✅ **Assess quality of prompts used during meeting** (not just pre-meeting)
- ✅ **Demonstrate AI consultation** as facilitator

**Example Application**:
**Minute 45 - AI Consultation Break:**
> "Everyone stop. You have 8 minutes. Use an AI assistant to ask ONE question that will help you make a better decision. When we reconvene, you'll share:
> 1. The prompt you used
> 2. What you learned
> 3. Whether it changed your thinking
> 
> I'll put a Google Form link in chat for you to submit your prompt before we resume."

**Assessment Integration**:
Add to rubric: "AI Collaboration Skills (10 points): Quality of prompt used during deliberation, appropriateness of question asked, and ability to integrate AI insights into argument."

---

### 2.4 Insufficient Exploration of Implementation Details

**What Happened**:
Discussion focused heavily on WHETHER to deploy AI, less on HOW to deploy it. Few questions about:
- What does "audit" actually entail?
- Who conducts the fairness review?
- How long does retraining really take?
- What are specific success metrics?

**Why It Matters**:
- Business decisions require implementation thinking
- "Devil is in the details" - execution matters as much as strategy
- Board members need to assess feasibility, not just desirability
- Real-world decisions require operational specifics

**Design Implications for Future Cases**:
- ✅ **Add implementation planning requirement** to pre-meeting assignment
- ✅ **Include "operational feasibility"** in rubric
- ✅ **Provide vendor proposals** with specific deliverables/timelines
- ✅ **Ask "HOW would this actually work?"** questions explicitly
- ✅ **Make some options fail due to implementation problems** in consequence scenarios

**Example Application**:
Pre-meeting Assignment Question 3:
> "Implementation Planning (10 points): Choose your preferred option. Develop a 90-day implementation plan including:
> - Key milestones and deliverables
> - Required resources (people, budget, time)
> - Success metrics (how will you know it's working?)
> - Risk mitigation strategies (what could go wrong? how will you address it?)
> - Stakeholder communication plan
> 
> Be specific. Generic answers will receive minimal credit."

---

### 2.5 Missing Stakeholder Voices

**What Happened**:
No one explicitly role-played as a denied applicant, a loan officer facing job loss, or a community member affected by discriminatory lending. Discussion stayed at board level.

**Why It Matters**:
- Empathy requires perspective-taking
- Real board decisions should consider stakeholder testimony
- Abstract "impact on minorities" < concrete "Maria's story"
- Business ethics requires imagining stakeholder experiences

**Design Implications for Future Cases**:
- ✅ **Include stakeholder testimonials** in case materials (video or written)
- ✅ **Assign stakeholder roles** to some participants
- ✅ **Create "stakeholder panel"** section in deliberation
- ✅ **Require "walk in their shoes" analysis** in assignments
- ✅ **Use consequence scenarios** to show specific human impacts

**Example Application**:
Case 2 includes:
- **Video testimonial 1**: Customer explaining frustration with current process (2 min)
- **Video testimonial 2**: Employee worried about job security (2 min)
- **Video testimonial 3**: Community advocate discussing impact (2 min)
- **Requirement**: Board must watch all three before deliberation
- **Assignment**: "Which stakeholder's concerns are most compelling? Why?"

**Alternative**: Assign roles:
- 14 board members vote
- 3 "stakeholder advisors" present perspectives but don't vote
- Advisors must prepare 3-minute presentations from their stakeholder's POV

---

## Part 3: Surprises & Unexpected Insights

### 3.1 The "Human Bias Baseline" Question Was Brilliant

**What Happened**:
Dan asked: "How do we know the humans aren't biased?" This simple question reframed the entire discussion by challenging the implicit assumption that human judgment is the unbiased baseline.

**Why This Was Important**:
- Best questions challenge assumptions
- Revealed that AI might be making *existing* bias visible, not creating new bias
- Sophisticated business thinking: always ask "compared to what?"
- Shifted conversation from "AI is bad" to "what's our real baseline?"

**What We Learned**:
- Build in more "challenge your assumptions" prompts
- Reward critical questioning in rubric
- Include counterfactual analysis in case design
- Teach "compared to what?" as business thinking skill

**Design Implications**:
✅ Add to every case: "What assumptions are you making? What if those assumptions are wrong?"
✅ Reward assumption-challenging in rubric
✅ Include data on both AI and human performance (when relevant)
✅ Teach comparative analysis as explicit skill

---

### 3.2 Generational Market Insight Was Underexplored

**What Happened**:
Dee made an excellent point about 30-year-old borrowers "working 70 hours a week" and wanting speed over relationship banking. This market segmentation insight didn't get picked up by others.

**Why This Matters**:
- Customer preferences are segmented by generation/demographics
- Students have real market knowledge - but it got lost
- Business strategy requires market understanding
- This is where their professional experience shines

**What We Learned**:
- Market/customer insights need explicit prompting
- Consider adding "customer analysis" to rubric
- Include demographic data in case materials
- Create space for market strategy discussion

**Design Implications**:
✅ Add customer persona analysis to pre-meeting assignments
✅ Include demographic/psychographic data in cases
✅ Ask: "Which customer segments benefit? Which are harmed?"
✅ Connect decisions to market positioning strategy

---

### 3.3 Students Are More Sophisticated Than Expected

**What Happened**:
Expected: Basic ethical reasoning, surface-level analysis  
Reality: Nuanced thinking, genuine trade-off recognition, sophisticated business reasoning

Notable examples:
- Rich's "35-year blind spot" reframing
- Brad's vendor dependency analysis
- Robert's risk assessment framework
- Jorge's persuasive stakeholder advocacy
- Ed's historical pattern recognition

**Why This Matters**:
- We can be more ambitious with case complexity
- They can handle multiple simultaneous constraints
- Don't need to "dumb down" for adult learners
- Professional experience is powerful prerequisite

**What We Learned**:
- Increase complexity for Cases 2-4
- Provide more sophisticated analytical tools
- Trust their business judgment
- Challenge them more, not less

**Design Implications**:
✅ Case 4 should be genuinely difficult
✅ Include real financial modeling
✅ Add time pressure (simulate real urgency)
✅ Multi-stakeholder complexity (competing interests)
✅ Ambiguous information (what you don't know matters)

---

### 3.4 Vote Changes Are Learning Moments (Celebrate Them!)

**What Happened**:
Ed explicitly changed his vote after hearing Jorge's arguments. This is evidence of:
- Active listening
- Intellectual humility  
- Genuine deliberation working
- Learning through dialogue

**Why This Matters**:
- This is the GOAL of deliberation
- Should be celebrated, not hidden
- Models good decision-making (update beliefs based on evidence)
- Shows simulation is working as intended

**What We Learned**:
- Track pre/post votes explicitly
- Reward vote changes
- Discuss vote changes in debrief
- Normalize uncertainty and belief updating

**Design Implications**:
✅ Add "Did you change your vote?" to Google Form
✅ Bonus points for explaining vote change
✅ Debrief should celebrate Ed's intellectual honesty
✅ Include "belief updating" as professional skill in rubric

---

## Part 4: Design Principles Evolved

Based on Case 1 implementation, here are refined design principles for Cases 2-4:

### 4.1 Balance Business + Ethics (Not Either/Or)

**Original Thinking**: Ethics-focused with business considerations  
**Revised Thinking**: Business-focused with ethics as risk factor

**Rationale**: 
- Course is "GenAI for Business Professionals" not "AI Ethics Philosophy"
- Students naturally integrate ethics into business thinking
- Ethics framed as business risk/opportunity resonates more
- This audience thinks in terms of ROI, market position, risk

**Implementation**:
- Lead with business problem
- Ethics emerges as business consideration
- Financial implications always included
- Reputational risk = business risk

---

### 4.2 Leverage Professional Experience Systematically

**Original Thinking**: Case-based learning with fresh eyes  
**Revised Thinking**: Case-based learning + explicit experience integration

**Rationale**:
- Students have 4-15+ years relevant experience
- Their knowledge is pedagogical asset
- Experience-based arguments are more persuasive
- Real-world connections deepen learning

**Implementation**:
- Add "professional experience" question to all pre-meeting assignments
- Budget time for experience sharing
- Invite analogies to situations they've faced
- Value experiential wisdom in rubric

---

### 4.3 Embed AI Tool Usage in Deliberation (Not Just Prep)

**Original Thinking**: Assess prompts in pre-meeting assignment  
**Revised Thinking**: Assess prompts in pre-meeting AND during deliberation

**Rationale**:
- Course focus is "advanced prompting techniques"
- Real business use = AI consultation during decision-making
- Demonstrates AI as thinking partner, not answer machine
- Creates authentic assessment opportunities

**Implementation**:
- Mandatory AI consultation break mid-deliberation
- Share prompts and insights in real-time
- Assess quality of questions asked
- Model effective AI collaboration as facilitator

---

### 4.4 Teach AI-Partnership for Analysis (Not Just Provide Tools)

**Original Thinking**: Provide analytical tools (spreadsheets, templates) for students to use  
**Revised Thinking**: Teach students to use AI as their analytical partner

**Rationale**:
- This is "Generative AI for Business Professionals" - focus on AI usage
- Students have varying finance/analytical backgrounds
- Goal is AI collaboration skills, not becoming financial analysts
- Real professionals use AI to help with complex analysis
- Prompt quality matters more than calculation ability

**Implementation**:
- Show examples of effective analytical prompts
- Require students to share prompts used for understanding data
- Assess their ability to ask AI good analytical questions
- Teach iterative prompting (follow-up questions based on AI responses)
- Critical evaluation of AI's reasoning (don't just accept answers)

**What Good AI-Assisted Analysis Looks Like**:

**Prompt 1**: "Explain the difference between Options 1 and 3 in terms of total 3-year costs, including both direct expenses and opportunity costs. What factors would make one option significantly more expensive than projected?"

**AI helps, student synthesizes**: "The AI showed me that Option 1 appears cheaper upfront ($800K vs $1.2M) but has higher risk of unexpected costs (legal liability, reputational damage). Option 3's audit costs are known and capped. When I asked about opportunity costs, the AI helped me see that Option 1's potential for customer loss could exceed the $400K difference."

**Prompt 2**: "Challenge the assumption that Option 2's 'fairness constraints' will only reduce efficiency by 5%. What could make the efficiency hit larger?"

**Critical evaluation**: "The AI suggested several factors the case doesn't mention: integration complexity, false positive rates, and loan officer workflow disruption. This made me realize the 5% figure is optimistic and we should budget for 10-15% efficiency reduction."

---

### 4.5 Structure Inter-Participant Dialogue Deliberately

**Original Thinking**: Open discussion will naturally produce debate  
**Revised Thinking**: Structured debate formats produce richer engagement

**Rationale**:
- Most comments went to instructor, not peers
- Real boards have direct debate
- Peer learning > instructor-student exchange
- Professional disagreement is learnable skill

**Implementation**:
- Direct response rounds
- Pair opposing viewpoints
- Require engaging with others' arguments
- Facilitate connections, not just calls on people

---

### 4.6 Increase Complexity Progressively

**Original Thinking**: Keep cases similar in complexity  
**Revised Thinking**: Case 4 should be significantly harder than Case 1

**Rationale**:
- They're more sophisticated than expected
- Learning requires challenge
- Final case should integrate all skills
- Rising difficulty = rising confidence

**Implementation**:
- Case 1: Foundation (what we did)
- Case 2: More complexity + AI-assisted analysis (teach prompting for business understanding)
- Case 3: Greater ambiguity (incomplete information)
- Case 4: Crisis simulation (time pressure + complexity + ambiguity)

### 4.7 AI as Thinking Partner, Not Answer Machine

**Principle**: Students should learn to collaborate with AI, not delegate to it or replace their own expertise

**What This Means**:
- AI explains complex concepts → student synthesizes into recommendations
- AI generates alternatives → student evaluates and chooses
- AI identifies risks → student decides which matter most  
- AI does calculations/analysis → student interprets what it means for decision

**In Practice**:
- Assess quality of prompts, not quality of AI's answers
- Require students to show their prompting process
- Value critical evaluation of AI reasoning
- Teach iterative prompting (follow-up based on AI responses)
- Distinguish: AI as thinking partner ✅ vs. AI as decision-maker ❌

**Why It Matters for This Course**:
- Course title: "Generative AI for Business Professionals"
- Course goal: "advanced prompting techniques"
- Students have varying analytical/finance backgrounds
- Real professional skill = knowing how to use AI effectively
- This IS the core course content - not becoming financial analysts

**Assessment Focus - Grade students on**:
- Quality of questions they ask AI
- Ability to critically evaluate AI's reasoning
- Synthesis of AI insights into their own judgment
- Recognition of AI limitations/blind spots
- Iterative refinement of prompts based on responses

**Example of Good AI Partnership**:

Student doesn't know NPV calculation → Weak approach: "Calculate NPV for me"  
Better: "Explain what NPV means and why it matters for comparing these options"  
Best: "Explain NPV in plain language, then help me understand which factors in this case would most affect the NPV calculation. What assumptions matter most?"

---

## Part 5: Specific Recommendations for Cases 2-4

### Case 2 Design Priorities:

1. **Include explicit build-vs-buy decision** (Brad's "control destiny" theme)
2. **Require AI-assisted financial/business analysis** (teach effective prompting for data interpretation)
3. **Add AI consultation break** mid-deliberation
4. **Include customer persona analysis** (leverage Dee's market insight) - use AI to help understand customer segments
5. **Create structured debate format** (direct participant-to-participant)
6. **Provide examples of strong analytical prompts** (teach AI partnership skills)

**Example Case 2 Topic**: 
Marketing AI tool that personalizes customer communications but requires extensive customer data collection. Vendor solution vs. internal development vs. hybrid approach.

**AI Skills Focus for Case 2**:
- Using AI to compare vendor proposals
- Prompting AI to identify hidden costs/risks
- AI-assisted customer segmentation analysis
- Critical evaluation of AI's recommendations

---

### Case 3 Design Priorities:

1. **Introduce mid-case information reveal** ("breaking news" email)
2. **Add time pressure element** (decision needed quickly)
3. **Include stakeholder testimonials** (video or written)
4. **Require implementation planning** (not just yes/no decision)
5. **Assign some stakeholder roles** (not everyone is board member)

**Example Case 3 Topic**:
Operational AI for supply chain optimization. Environmental costs (energy usage) vs. efficiency gains. Union concerns about automation. International supplier implications.

---

### Case 4 Design Priorities:

1. **Crisis simulation format** (something has already gone wrong)
2. **Maximum complexity** (multiple simultaneous constraints)
3. **Required board roles** (CFO, CRO, etc. - specific responsibilities)
4. **Real-time scenario evolution** (instructor introduces complications)
5. **Integration of all skills** (financial + ethical + strategic + AI tools)

**Example Case 4 Topic**:
Company deployed AI system (Case 2 or 3 decision). Now there's a problem (bias discovered, system failed, regulatory investigation, whatever). Board must respond to crisis. Multiple stakeholders demanding action. Media involved. Clock is ticking.

---

## Part 6: Rubric Refinement

### Current Rubric (Case 1):
- Prompt Sophistication: 35%
- Ethical Awareness: 35%
- Business Acumen: 30%

### Proposed Rubric (Cases 2-4):
- **Prompt Sophistication: 35%** (maintain - this is course focus)
- **Business Acumen: 35%** (increase - better reflects course goals)
- **Ethical Awareness: 30%** (decrease - still important but as business risk factor)

### Rationale:
- Course is "GenAI for **Business** Professionals"
- Students demonstrated strong business thinking
- Ethics matters but as business consideration
- Better alignment with course description

### Additional Rubric Categories to Consider:

**Data Analysis (could be subset of Business Acumen)**:
- Engagement with case numbers
- Financial modeling quality
- Quantitative reasoning

**Collaboration & Deliberation (could be separate category)**:
- Quality of inter-participant engagement
- Intellectual humility (changing mind)
- Professional disagreement skills

**Implementation Thinking (could be subset of Business Acumen)**:
- Operational feasibility assessment
- Timeline and resource realism
- Risk mitigation planning

---

## Part 7: Facilitation Techniques to Adopt

### 7.1 The AI Consultation Break

**When**: Minute 45 of 120-minute session  
**Duration**: 8-10 minutes  
**Format**:
1. "Everyone stop deliberating"
2. "Use AI tool of your choice"
3. "Ask ONE question to help you decide"
4. "Submit prompt in Google Form"
5. "Share what you learned when we reconvene"

**Assessment**: Review prompts for quality, specificity, strategic thinking

---

### 7.2 Direct Debate Rounds

**When**: After initial statements (minute 30-60)  
**Format**:
1. Identify 2-3 main positions
2. Select advocates for each
3. 3-minute opening statement each
4. 2-minute direct responses
5. Open deliberation

**Benefit**: Forces peer-to-peer engagement, not just instructor-mediated

---

### 7.3 Experience Share Session

**When**: First 10 minutes OR pre-meeting assignment  
**Format**: "Who here has faced a similar decision? Share your story (2 minutes)."

**Benefit**: Activates professional knowledge, creates connection, adds realism

---

### 7.4 Assumption Challenge Moment

**When**: Mid-deliberation  
**Format**: "What assumptions are we making? What if those assumptions are wrong?"

**Benefit**: Develops critical thinking, surfaces blind spots (like Dan's question)

---

### 7.5 Vote Tracking & Reflection

**Format**:
- Pre-meeting vote (in assignment)
- Mid-deliberation informal poll
- Post-deliberation formal vote (Google Form)
- Post-consequence reflection

**Benefit**: Makes learning visible, celebrates belief updating

---

## Part 8: What NOT to Change

These elements worked well and should be maintained:

✅ **Board of Directors framing** - Creates professional accountability  
✅ **5 options structure** - Provides rich deliberation space  
✅ **Consequence scenarios with stochasticity** - Teaches decision-making under uncertainty  
✅ **Pre-meeting assignments** - Students came prepared  
✅ **Simple majority voting** - Clear, decisive  
✅ **Google Forms for voting** - Easy to implement  
✅ **Case-based learning approach** - Engaging and realistic  
✅ **Multiple industries/functions** - Keeps it fresh  
✅ **Respectful deliberation culture** - Should be reinforced, not changed

---

## Part 9: Questions for Future Exploration

### 9.1 How much does vote outcome matter for grading?

Currently: Grade on quality of thinking, not position taken  
Question: Should we reward "correct" decision (in hindsight after consequences)?

**Recommendation**: Continue grading on reasoning quality, but add reflection on consequences. "Given what happened, what would you do differently?" This assesses learning without punishing reasonable decisions with bad outcomes.

---

### 9.2 Should we pre-assign stakeholder roles or allow self-selection?

Case 1: Everyone was board member  
Future: Some stakeholder advisors?

**Recommendation**: Case 3 experiment with 3 assigned stakeholder advisors + 14 board members. Evaluate engagement and learning.

---

### 9.3 How much facilitator intervention is optimal?

Case 1: Instructor-mediated discussion  
Question: More facilitation or less?

**Recommendation**: Progressively reduce instructor intervention. By Case 4, students should be leading their own deliberation with minimal facilitation.

---

### 9.4 Should consequences be revealed before or after next case?

Case 1 Plan: Reveal consequences at start of Session 2  
Question: Does this create good continuity or muddy the waters?

**Recommendation**: Reveal consequences at START of next session (5-10 min), then pivot to new case. Creates narrative continuity and allows reflection before new challenge.

---

## Part 10: Success Metrics

### How do we know the simulation is working?

**Evidence from Case 1**:
✅ High engagement (2+ hour discussion, nobody checked out)  
✅ Sophisticated reasoning (multiple A/A- level contributions)  
✅ Genuine disagreement (not everyone agreeing with instructor)  
✅ Vote changes (Ed's shift shows deliberation working)  
✅ Real-world connections (Ed's mortgage story, others' experience)  
✅ Respectful discourse (professional disagreement maintained)  
✅ Preparation evident (referenced case details)  

**Metrics to track going forward**:
- Percentage who change votes pre→post deliberation
- Quality of prompts used during AI consultation breaks
- Depth of financial analysis in assignments
- Frequency of peer-to-peer dialogue (vs. instructor-mediated)
- Post-course feedback on simulation effectiveness
- Self-reported confidence in AI decision-making

---

## Part 11: Risk Factors to Monitor

### 11.1 Groupthink Risk

**Risk**: Everyone converges on same answer too quickly  
**Mitigation**: Assign devil's advocate role, reward dissent, maintain 5 options

### 11.2 Time Management

**Risk**: Deliberations run too long or too short  
**Mitigation**: Structured agenda with time boxes, facilitate pacing

### 11.3 Unequal Participation

**Risk**: Some students dominate, others silent  
**Mitigation**: Structured response rounds, call on quiet participants, track participation

### 11.4 AI Tool Over-Reliance

**Risk**: Students let AI decide for them  
**Mitigation**: Assess prompts for critical thinking, reward AI as "thinking partner" not "answer source"

### 11.5 Analysis Paralysis

**Risk**: Too much complexity → students freeze  
**Mitigation**: Provide analytical tools/templates, scaffolding for Case 2-3 before full complexity in Case 4

---

## Part 12: Implications for Course Design

### 12.1 Syllabus Adjustments

**Consider adding**:
- Explicit learning objective: "Use AI tools during real-time decision-making"
- Participation grade component for quality of deliberation
- Bonus points for documented belief changes
- Required use of specific analytical tools

### 12.2 Blackboard Organization

**Improvements**:
- Create discussion forum for pre-meeting debate
- Provide analytical tool templates in assignments
- Make consequence scenarios visible after revelation
- Post exemplary prompts from AI consultation breaks

### 12.3 Assessment Philosophy

**Key Principle**: Assess thinking quality, not agreement with instructor

**Evidence of quality thinking**:
- Engages with case specifics (not just generalizations)
- Recognizes trade-offs explicitly
- Questions own assumptions
- Considers stakeholder impacts
- Uses AI strategically (not dependently)
- Updates beliefs based on new information

---

## Part 13: Looking Ahead

### Case 2 Design Session Priorities:

1. ✅ Select industry/functional area (Marketing? Operations? R&D?)
2. ✅ Build in build-vs-buy decision
3. ✅ Create financial analysis template
4. ✅ Design AI consultation break
5. ✅ Structure direct debate format
6. ✅ Include customer persona analysis
7. ✅ Draft stakeholder testimonials

### Case 3 Design Session Priorities:

1. ✅ Introduce mid-case information reveal
2. ✅ Add time pressure element
3. ✅ Assign stakeholder roles (experiment)
4. ✅ Require implementation planning
5. ✅ Create operational complexity

### Case 4 Design Session Priorities:

1. ✅ Crisis simulation format
2. ✅ Assign specific board roles (CFO, CRO, etc.)
3. ✅ Maximum complexity integration
4. ✅ Real-time scenario evolution capability
5. ✅ Comprehensive skills assessment

---

## Appendix: Key Quotes from Case 1 Deliberation

These quotes capture the quality of student thinking and should inform future case design:

**Rich**: *"The bank has been controlling its own activities for 35 years and never knew that its policies were discriminatory and seemingly never even bothered to measure that."*

**Brad**: *"I just don't think that's realistic in the real world that you can trust that another business is gonna be able to guarantee that they will fix it perfectly."*

**Dee**: *"The mom and pop bank might be great if you're over the age of 55, but if you're 30 ready to get that loan, we are not going to the mom and pop location because we're working 70 hours a week already."*

**Robert**: *"Our responsibility as board members is to assess risk... at 10 to 15% risk in normal business, that's acceptable risk."*

**Ed**: *"I remember my wife coming home one day and saying, the boss wants us to have 10 minutes to make a decision on a residential mortgage... there's plenty of room to make mistakes... we all know that kind of blew up in 2008."*

**Dan**: *"How do we know the humans aren't biased?"*

**Jorge**: *"We're steamrolling minority communities... this is a relationship bank."* (paraphrased)

---

## Final Reflection

**The simulation format is working exceptionally well.** Students are engaged, prepared, thoughtful, and professional. The deliberations demonstrate sophisticated business reasoning integrated with ethical awareness. 

**Key insight**: These are not traditional college students - they're experienced business professionals who bring tremendous practical wisdom to the cases. Our job is to create scenarios that activate their expertise while teaching them new skills (AI collaboration, systematic ethical analysis, structured decision-making under uncertainty).

**Moving forward**: Build on what worked (board format, consequence scenarios, 5 options, professional framing) while addressing gaps (financial analysis tools, AI consultation during deliberation, inter-participant dialogue structure, stakeholder perspective-taking).

**The goal**: By Case 4, students should be confidently using AI tools as thinking partners, making complex business decisions that integrate ethical considerations, and demonstrating the professional judgment expected of board members.

---

**Next Steps**: 
1. Use these lessons to design Case 2
2. Implement recommended facilitation techniques
3. Monitor success metrics
4. Continue iterating based on evidence

*Document prepared by: Claude (Sonnet 4.5)*  
*Date: November 27, 2025*  
*Based on: Case 1 transcript analysis + deliberation observation*
