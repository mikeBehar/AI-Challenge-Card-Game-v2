# Case 2: Ideal Answers & Scoring Guide
**TrendSetters Retail - Marketing AI Decision**

---

## Overview

This document provides guidance for assessing student responses to the Case 2 pre-meeting assignment. 

**Assessment Philosophy**:
- Reward quality of thinking, not position taken
- Value business + ethics integration (not separate)
- Assess AI collaboration skills, not domain expertise
- Give credit for recognizing trade-offs and complexity

**Rubric Integration**:
All scoring uses the Master Rubrics document:
- **Prompt Quality** (Section 1): 35% weight
- **Business Acumen** (Section 5): 35% weight  
- **Ethical Awareness** (Section 6): 30% weight

---

## Question 1: Build-vs-Buy Analysis & Vendor Dependency

### Point Distribution (10 points total)
- Part A - Organizational autonomy comparison: 3 points
- Part B - Application of Brad's principle: 3 points
- Part C - Contract protections: 4 points

### Scoring Breakdown

**Business Acumen (6 points - 60%)**:
- Realistic about vendor dependency risks
- Understands organizational control trade-offs
- Practical about contract negotiations

**Ethical Awareness (4 points - 40%)**:
- Considers stakeholder impacts of vendor relationship
- Recognizes autonomy as organizational value
- Addresses privacy/data control issues

---

### Part A: Exemplary Answer Elements

**Strong responses will compare on multiple dimensions**:

**Option 1 (Buy Vendor) - What You Gain**:
- Speed to market (3-4 months vs. 18-24 months)
- Proven technology with reference customers
- Vendor expertise and ongoing optimization
- Lower Year 1 cost ($850K vs. $1.2M)
- No hiring/retention risk for AI talent

**Option 1 (Buy Vendor) - What You Lose**:
- **Control over roadmap**: Nexus decides which features to build, when, and priorities
- **Pricing power**: Locked into vendor pricing; they could 3X fees after renewal
- **Data control**: Customer data sits on vendor servers (even if encrypted)
- **Customization limits**: Can't build TrendSetters-specific features vendor doesn't support
- **Exit costs**: Switching vendors means starting over; customer insights stay with Nexus
- **Dependency**: Critical business capability (personalization) depends on vendor's health/priorities

**Option 2 (Build Internal) - What You Gain**:
- **Complete control**: Own the algorithms, features, data, roadmap
- **IP ownership**: Build proprietary capability that's hard for competitors to copy
- **Data sovereignty**: All customer data stays internal, no third-party access
- **Customization freedom**: Build exactly what TrendSetters needs, not generic solution
- **Organizational capability**: Team can work on other AI projects beyond marketing
- **No vendor risk**: Not dependent on Nexus staying in business or maintaining product

**Option 2 (Build Internal) - What You Lose**:
- Time to market (18-24 months means competitors pull ahead)
- Certainty of results (might fail entirely; no proven track record)
- Vendor sophistication (v1.0 won't match vendor's mature platform)
- Flexibility to exit (can't cancel subscription; committed to maintaining team)
- Higher ongoing costs ($680K annual vs. $420K vendor)

**Example of Exceptional Answer**:

> "Option 1 (vendor) vs. Option 2 (build) represents a classic control-vs-speed trade-off. With CustomerIQ, TrendSetters gains speed (3-4 months to deployment vs. 18-24 months internal build) and de-risks execution (proven platform vs. uncertain internal capability). However, they surrender organizational autonomy in critical ways: (1) Roadmap control—Nexus decides product direction, not TrendSetters; (2) Pricing power—after we're dependent, Nexus can increase fees with little recourse; (3) Data sovereignty—customer insights live on vendor servers; (4) Exit costs—switching vendors means rebuilding from scratch since we don't own the IP.
>
> Building internal flips these trade-offs. We control everything—features, data, pricing, roadmap—and own the IP. This matters especially for a company like TrendSetters that positions on 'conscious consumer' values; owning our personalization capability aligns with brand autonomy. However, we lose speed (competitors gain 12-18 month head start) and accept execution risk (team might fail to deliver, or take longer than projected). The $260K annual cost delta ($680K internal vs. $420K vendor) is real but manageable if we value organizational control.
>
> The deeper trade-off is strategic positioning: does TrendSetters compete on personalization sophistication (favors fast vendor deployment) or on differentiated, values-aligned customer relationships (favors slower but controlled internal build)? Given TrendSetters' 'conscious consumer' brand, vendor dependency on a VC-backed startup with aggressive data collection practices feels misaligned."

**What makes this exceptional**:
- ✅ Specific comparisons on multiple dimensions (speed, cost, control, risk)
- ✅ Quantifies trade-offs ($260K cost delta, 12-18 month time delta)
- ✅ Connects decision to company strategy and brand values
- ✅ Shows nuanced thinking (not "one option is obviously better")
- ✅ References organizational autonomy as a value, not just a tactic

---

### Part B: Exemplary Answer Elements

**Brad's Case 1 Principle**: "Control your own destiny" - don't rely on external vendors to fix your critical problems because you can't trust they'll prioritize your needs or deliver on promises.

**Strong responses will**:
- Articulate Brad's principle clearly
- Analyze whether it applies to this situation
- Note similarities AND differences from Case 1
- Take a position with reasoning

**Argument that Brad's principle DOES apply here**:

> "Brad's principle absolutely applies. Marketing personalization isn't a peripheral capability—it's becoming core to competing in retail, just like loan screening was core to Liberty Regional's banking business. If we choose Option 1, we're outsourcing a critical competitive capability to a VC-backed startup. What happens if Nexus:
> - Raises prices 200% at renewal (we're locked in)?
> - Gets acquired and new owner kills the product?
> - Prioritizes enterprise clients and neglects mid-market customers like us?
> - Suffers data breach and our customer data is compromised?
>
> Brad was right: when you delegate critical problems to vendors, you lose control over your destiny. The 12-18 month delay to build internal is painful, but it's the price of organizational autonomy in a critical capability."

**Argument that Brad's principle DOESN'T fully apply (or applies differently)**:

> "Brad's principle is important but this situation differs from Case 1 in key ways. At Liberty Regional, the vendor (FinTech Solutions) was the ONLY party who could audit/fix the biased AI—the bank lacked capability entirely. Here, TrendSetters HAS options: we could pilot (Option 4), go hybrid (Option 3), or even enhance manual approaches (Option 5). We're not completely dependent on Nexus.
>
> Also, marketing personalization is more fungible than loan screening. If CustomerIQ fails us, we can switch to a competitor (Klaviyo, Segment, etc.) or fall back to manual approaches. We don't lose our banking license or face regulatory action like Liberty could have. The switching costs are real but not existential.
>
> That said, Brad's intuition about vendor dependency is right—Option 1 does create risk. That's why Option 3 (hybrid) or Option 4 (pilot) might thread the needle: get vendor speed while building internal capability to reduce long-term dependency."

**What makes these answers strong**:
- ✅ Clearly articulates Brad's principle from Case 1
- ✅ Analyzes specific similarities/differences in context
- ✅ Takes a position with reasoning
- ✅ Shows application of learning across cases

---

### Part C: Exemplary Answer Elements

**Strong responses will propose specific, actionable contract provisions** (not just "negotiate better terms"):

**Excellent Contract Protections to Reduce Lock-In Risk**:

1. **Price Protection Clause**:
   - "Annual licensing fee increases capped at inflation + 5% for first 5 years"
   - "If Nexus raises prices beyond cap, TrendSetters has 90-day exit right with full data export"
   - Prevents: Nexus exploiting lock-in by 3X-ing prices after we're dependent

2. **Data Portability & Export Rights**:
   - "TrendSetters owns all customer data, insights, and ML model outputs"
   - "Upon contract termination, Nexus must provide: (a) raw customer data, (b) trained model weights, (c) complete documentation of algorithms and features, within 30 days"
   - "No restriction on using exported data with competing platforms"
   - Prevents: Holding our data hostage; enables switching to competitor or internal solution

3. **Service Level Agreements (SLAs) with Teeth**:
   - "99.5% uptime guarantee with financial penalties: 10% monthly fee rebate for each 0.5% below SLA"
   - "Feature roadmap commitments: Specific features (to be defined) delivered within 12 months or contract cancellation right"
   - Prevents: Nexus deprioritizing our requests or letting platform degrade

4. **Competitive Non-Use Clause**:
   - "Nexus may not share TrendSetters' specific data, insights, or custom features with direct competitors (defined as mid-market fashion retailers)"
   - "Our customer data may not be used to train models for competing clients"
   - Prevents: Our customer insights helping competitors who also use CustomerIQ

5. **Exit Assistance Clause**:
   - "If contract terminates for any reason, Nexus will provide 6 months of technical support to facilitate migration to alternative platform"
   - "Includes documentation, training, and technical consultation at no additional cost"
   - Prevents: Nexus making exit so painful we're forced to stay

6. **Change of Control Protection**:
   - "If Nexus is acquired, TrendSetters has option to: (a) terminate contract with 60-day notice and full data export, OR (b) continue at same terms for remainder of contract period"
   - Prevents: New owner changing terms or killing product

**Example of Exceptional Answer**:

> "To reduce lock-in risk in Option 1, TrendSetters should negotiate three critical protections:
>
> **1. Price Protection**: Cap annual fee increases at CPI + 5% for 5 years, with termination right if exceeded. Without this, Nexus could triple fees once we're dependent (their investor pressure to maximize revenue is real). The case shows licensing is $290K/year—if they 3X it to $870K in Year 3, we're trapped.
>
> **2. Complete Data Portability**: Contract must specify we OWN all customer data, ML model outputs, and insights. Upon termination (for any reason), Nexus provides: raw data, model weights, algorithm documentation, within 30 days. This makes switching to a competitor or building internal feasible. Without this, our customer insights stay with Nexus when we leave—we'd start from zero.
>
> **3. Change of Control Exit Right**: If Nexus is acquired (realistic for VC-backed startup), we can terminate with 60 days notice and full data export. Example: What if Amazon buys Nexus and wants the data to compete with us, or new owner kills the mid-market product tier? We need an exit.
>
> These three provisions don't eliminate vendor dependency, but they make it survivable. We can exit if Nexus fails to deliver, raises prices unreasonably, or gets acquired by someone hostile to our interests. This addresses Brad's concern without sacrificing the speed advantage of Option 1."

**What makes this exceptional**:
- ✅ Three specific, concrete provisions (not generic "negotiate better terms")
- ✅ Explains WHY each matters (the risk it mitigates)
- ✅ References case facts (licensing costs, startup status)
- ✅ Realistic about what's negotiable and what problems it solves
- ✅ Acknowledges these reduce but don't eliminate risk

---

## Question 2: Customer Segmentation & Generational Divide

### Point Distribution (10 points total)
- Part A - Best option for each segment: 4 points
- Part B - Serving both vs. different strategies: 3 points
- Part C - Application of Dee's insight: 3 points

### Scoring Breakdown

**Business Acumen (5 points - 50%)**:
- Sophisticated market segmentation thinking
- Understands customer psychology and expectations
- Practical about serving different segments

**Ethical Awareness (3 points - 30%)**:
- Considers different stakeholder (customer) perspectives
- Addresses privacy concerns as varying by segment
- Recognizes generational fairness questions

**Prompt Sophistication (2 points - 20%)**:
- If student used AI to understand customer segments
- Quality of customer analysis prompts

---

### Part A: Exemplary Answer Elements

**Strong responses analyze each segment's needs**:

**Under-35 Segment ("Digital Natives")**:

**Characteristics** (from case):
- Want speed, convenience, AI recommendations
- Less concerned about privacy ("nothing to hide")
- Expect Netflix/Spotify-level personalization
- Shop primarily mobile, often late at night
- Value being "understood" by brands

**Best Option for Under-35**: **Option 1 (Buy Full Vendor)**

**Why**:
- Fastest deployment (3-4 months) matches their expectations for immediate gratification
- Sophisticated AI features (dynamic pricing, predictive recommendations) appeal to tech-savvy segment
- Social media integration and mobile optimization built in
- These customers WANT the personalization vendor offers—they're less bothered by data collection
- Facial recognition in stores? They probably won't care (they accept it in airports, phones, social media)

**45+ Segment ("Privacy-Conscious Traditionalists")**:

**Characteristics** (from case):
- Value in-store experience and human service
- Skeptical of data collection and AI
- Privacy-conscious ("I don't want to be tracked")
- Shop during business hours, often in-store
- Trust relationship over algorithm

**Best Option for 45+**: **Option 5 (Enhanced Manual Personalization)**

**Why**:
- Human specialists can provide the "personal stylist" experience this segment values
- No privacy concerns—no facial recognition, no third-party data
- Aligns with TrendSetters' "relationship bank" approach (wait, that's Case 1... I mean relationship-oriented retail)
- Can serve this segment in-store where they prefer to shop anyway
- Maintains brand differentiation on "conscious consumer" values this segment cares about

**Example of Strong Answer**:

> "For **under-35 customers**, Option 1 (full vendor solution) is optimal. This segment expects Amazon-level personalization—the case shows 82% say 'other retailers seem to know what I like better.' They want AI recommendations, dynamic pricing that optimizes for their shopping patterns, and mobile-first experience. CustomerIQ delivers all of this in 3-4 months. Critically, this segment is less privacy-sensitive; they've grown up with algorithmic recommendations and accept data collection as the price of personalization. The vendor's facial recognition and social media monitoring won't bother them—they already accept this on Instagram and TikTok.
>
> For **45+ customers**, Option 5 (enhanced manual) is better. This segment values human judgment over algorithms and cares deeply about privacy—they don't want to be tracked in stores or have their data sold to brokers. Three marketing specialists can provide the 'personal stylist' experience this segment wants, creating relationship-based loyalty that AI can't match. This also aligns with TrendSetters' 'conscious consumer' brand positioning, which likely resonates more with older customers anyway. The case shows same-store sales declining 6%—maybe because in-store experience (where 45+ shops) isn't differentiated enough? Better human service could fix this."

**What makes this strong**:
- ✅ Analyzes BOTH segments separately
- ✅ References specific case data (82% stat, same-store sales)
- ✅ Matches options to segment needs with clear reasoning
- ✅ Shows understanding of generational psychology (why each segment feels differently about AI/privacy)

---

### Part B: Exemplary Answer Elements

**The Core Question**: Can one solution serve both segments, or does TrendSetters need different approaches?

**Argument for ONE solution serving both**:

> "Option 3 (Hybrid) or Option 4 (Pilot) could serve both segments by implementing personalization **optionally**. Deploy CustomerIQ for customers who opt-in (likely under-35) while maintaining enhanced manual approach for those who opt-out (likely 45+). 
>
> Implementation: During account setup (web or in-store), customers choose their preference:
> - 'Personalized Experience' (AI-driven, requires data collection consent) → CustomerIQ
> - 'Classic Experience' (human-curated, minimal data collection) → Manual approach
>
> This respects customer autonomy, serves both segments appropriately, and positions TrendSetters as customer-choice-oriented brand. Downside: operational complexity of running two systems. But luxury retailers already do this (high-touch concierge service vs. self-service) so it's feasible."

**Argument for DIFFERENT strategies required**:

> "One solution cannot optimally serve both segments—trying to do so will satisfy neither. Better approach: **segment-specific strategies**.
>
> **For under-35 (60% of customer base, 75% of growth)**: Deploy Option 1 or 4 aggressively. This is where future revenue lives. Prioritize AI personalization, mobile optimization, social integration. Market as 'AI-powered style discovery.'
>
> **For 45+ (40% of customer base, declining)**: Maintain/enhance Option 5 approach in physical stores. Don't try to force AI on customers who don't want it. Market as 'expert personal styling.'
>
> Essentially, TrendSetters becomes TWO brands under one name: AI-forward e-commerce for younger customers, relationship-based retail for older customers. This matches how each segment already shops (mobile vs. in-store). Is it complex? Yes. But serving everyone the same way is why TrendSetters is 'lost in the middle' per the case."

**What makes these answers strong**:
- ✅ Takes clear position on whether one solution works
- ✅ Proposes specific implementation approach
- ✅ Acknowledges trade-offs (complexity, cost)
- ✅ References case context ("lost in the middle" positioning problem)

---

### Part C: Exemplary Answer Elements

**Dee's Case 1 Insight**: "The mom-and-pop bank might be great if you're over 55, but if you're 30 ready to get that loan, we're not going to the mom-and-pop location because we're working 70 hours a week already."

**Application to TrendSetters**:

**Strong responses connect Dee's insight to this case**:

> "Dee's insight is directly applicable: **younger customers expect speed and digital convenience as table stakes**. Just as 30-year-olds won't wait 14 days for loan approval when fintech offers 48 hours, younger shoppers won't tolerate generic email blasts when Amazon sends hyper-personalized recommendations.
>
> The case data confirms this: email CTR is 2.8% (below 3.5% industry average) and 68% of customers never return. Why? Because TrendSetters' marketing feels like 'mom-and-pop' retailer approach in an AI-powered world. Under-35 customers are 'working 70 hours a week' (metaphorically)—they want the retailer to know their style preferences, remember their size, predict what they'll want. They'll reward brands that save them time with AI.
>
> This is why doing nothing (Option 5) or moving too slowly (Option 2's 18-24 months) risks losing this segment entirely. They won't wait for TrendSetters to 'get there eventually'—they'll shop at competitors who already deployed AI personalization. Dee's lesson: match the customer segment's expectations for how business should work in 2025, not 2010."

**What makes this strong**:
- ✅ Directly quotes or closely references Dee's specific argument
- ✅ Draws clear parallel between Case 1 (loans) and Case 2 (retail)
- ✅ Uses case data to support the connection (68% one-time buyers, email CTR)
- ✅ Applies insight to decision framework (favors faster options)

---

## Question 3: AI-Assisted Financial & Risk Analysis

### Point Distribution (10 points total)
- Three prompts + purposes + learnings: 7 points (Prompt Sophistication)
- Synthesis paragraph: 2 points (Business Acumen)
- Critical evaluation of AI: 1 point (AI Collaboration)

### Scoring Breakdown

**Prompt Sophistication (7 points - 70%)**:
- Quality of prompts (specific, strategic, iterative)
- Purpose explanations (why asking each question)
- Learning articulation (what AI taught them)

**AI Collaboration (2 points - 20%)**:
- Critical evaluation of AI's responses
- Recognition of AI limitations or blind spots
- Synthesis in own words

**Business Acumen (1 point - 10%)**:
- Financial synthesis makes business sense
- Practical application of AI insights

**Reference**: Master Rubrics Sections 1 and 3

---

### Exemplary Prompts & Explanations

**Prompt 1 Example - Financial Analysis**:

> **Prompt**: "I'm evaluating five options for a $180M retailer facing declining revenue. The options range from $280K (pilot) to $1.2M (internal build) in Year 1. Help me calculate the 3-year total cost of ownership for Option 1 (buy vendor: $850K Y1, $420K ongoing) vs. Option 2 (build internal: $1.2M Y1, $680K ongoing). 
>
> Then factor in opportunity costs: What revenue might we lose if Option 2 takes 18 months vs. Option 1's 3 months deployment? Assume the vendor's promised 15% increase in average order value and 12% retention improvement. If our current average order is $85 and we have 2.3M customers, what's the 15-month revenue opportunity cost of choosing slower option?"
>
> **Purpose**: I asked this because I need to understand whether the upfront cost difference ($350K more for build) is outweighed by the opportunity cost of slower deployment. The case gives lots of numbers but doesn't calculate the time value of getting results faster. I want AI to help me think through whether "speed to revenue" justifies vendor cost.
>
> **What I Learned**: AI calculated 3-year TCO as $1.69M (vendor) vs. $2.56M (internal)—a $870K difference favoring vendor. But more importantly, AI showed that if vendor delivers promised 15% AOV increase ($12.75 more per order) and 12% better retention, the 15-month head start from Option 1 could generate $8-12M in incremental revenue. Even at conservative 20% of vendor promises ($2-3M revenue gain), that dwarfs the $870K cost difference. This makes the "build is cheaper" argument look wrong when you include opportunity costs.
>
> **Critical Evaluation**: AI made optimistic assumptions—it assumed vendor delivers 100% of promised benefits immediately. More realistic: 6-month ramp period and maybe 60-70% of promised improvements. Also, AI didn't factor in the potential for Option 2 to exceed vendor capabilities after 2-3 years (owns IP, can keep innovating). Should ask follow-up about longer time horizons.

**What makes this excellent**:
- ✅ Highly specific prompt with context, numbers, constraints
- ✅ Asks AI to calculate something student couldn't easily do themselves
- ✅ Clear purpose explanation showing strategic thinking
- ✅ Articulates key learning (opportunity costs matter more than upfront costs)
- ✅ Critical evaluation identifying AI's optimistic assumptions

**Prompt 2 Example - Risk Assessment**:

> **Prompt**: "What are three scenarios where Option 2 (build internal AI capability for $1.2M) ends up costing significantly MORE than projected? Consider: (1) difficulty recruiting ML engineers in Portland vs. Silicon Valley, (2) project delays beyond 18-24 month estimate, (3) first version failing to deliver promised functionality and needing rebuild. 
>
> For each scenario, estimate the additional cost and probability. Then tell me: at what probability-weighted expected cost does Option 2 become MORE expensive than Option 1's simple vendor solution?"
>
> **Purpose**: The case presents Option 2 as taking longer but "owning the capability." I'm skeptical—building software is notoriously hard and often fails. I want AI to help me think through realistic failure modes and their costs, not just the optimistic case. This helps me assess whether "control your destiny" is worth the execution risk.
>
> **What I Learned**: AI identified specific risks I hadn't thought about: (1) Salary competition—might need $220K/engineer (not $180K) to recruit in Portland; (2) Infrastructure costs could be 50% higher than estimated if data volumes exceed projections; (3) If project takes 30 months instead of 18, that's additional $420K in salary costs PLUS 12 more months of lost competitive ground. AI estimated reasonable downside case at $3.2M over 3 years (vs. $2.56M base case)—nearly double Option 1.
>
> **Critical Evaluation**: AI was helpful in identifying specific risk factors, but it couldn't really estimate probabilities well. Saying "30% chance of delay" is a guess, not data-driven. Also, AI didn't consider upside scenarios (what if build succeeds and creates 10% competitive advantage vendor can't match?). Risks cut both ways.

**What makes this excellent**:
- ✅ Asks AI to stress-test assumptions (not just confirm them)
- ✅ Requests specific scenarios with cost estimates
- ✅ Purpose shows desire to challenge optimistic projections
- ✅ Learning includes specific risks not obvious in case
- ✅ Critical evaluation notes AI can't estimate probabilities well

**Prompt 3 Example - Challenge Assumptions**:

> **Prompt**: "Challenge this assumption: 'Building internal AI capability takes 18-24 months to match vendor functionality.' What if we're underestimating how hard this is? Research similar mid-market retailers who tried to build personalization engines internally. How many succeeded vs. failed? What did successful builds have in common? What were common failure modes?"
>
> **Purpose**: The case treats 18-24 months as realistic timeline, but is it? I've read that most internal AI projects fail or take 2-3X longer than estimated. I want AI to find real-world examples of similar attempts to ground-truth the assumptions. This could change whether Option 2 is even feasible.
>
> **What I Learned**: AI found several examples: ModCloth tried internal build, took 36 months and $4M, ultimately shut down the project and switched to vendor. Everlane successfully built internal capability but they had ML expertise already and it still took 28 months. Stitch Fix succeeded but hired 50+ data scientists—way bigger than TrendSetters' 2-3 person plan. Pattern: successful internal builds either took much longer than projected OR required far more resources than mid-market retailer can afford. This makes me very skeptical of Option 2's feasibility.
>
> **Critical Evaluation**: AI helped find relevant examples I wouldn't have known about. However, I can't verify these examples are accurate—I should Google them separately to confirm. Also, these examples are from 2018-2020; maybe AI tooling has gotten easier since then? Should ask follow-up about whether GPT-4/Claude make building personalization engines easier in 2025 vs. 2020.

**What makes this excellent**:
- ✅ Explicitly asks AI to challenge an assumption in the case
- ✅ Requests real-world examples for grounding
- ✅ Purpose shows healthy skepticism about case's optimistic timeline
- ✅ Learning includes specific examples with outcomes
- ✅ Critical evaluation recognizes need to verify AI's examples

---

### Synthesis Paragraph - Exemplary Elements

**Strong synthesis integrates AI insights into business recommendation**:

> "Based on AI-assisted analysis, **Option 4 (pilot) makes the most financial sense** over 3 years. Here's why: While Option 1 (vendor) appears cheaper at 3-year TCO ($1.69M vs. $2.56M for build), and offers faster deployment (3 months vs. 18+), the breaking news about CustomerIQ's privacy breach makes the full commitment risky. Option 4 lets us test vendor results ($280K for 6 months) before committing another $520K. If the pilot hits vendor's promised metrics (15% AOV increase, 12% better retention), we expand; if it underdelivers or privacy concerns escalate, we exit for $50K and consider Option 2 or 3.
>
> AI helped me identify that opportunity costs matter more than I thought—the 15-month speed difference between vendor (4 months) and build (18+ months) could be worth $2-3M in revenue if personalization works. This favors faster options. However, AI also surfaced that internal builds often take 2-3X longer and cost more than estimated, with high failure rates for mid-market retailers. This makes Option 2 riskier than it appears.
>
> What AI got wrong or I'd probe deeper: (1) AI couldn't assess the probability that Nexus fixes their privacy issues vs. having more breaches—that's judgment, not calculation. (2) AI assumed vendor delivers promised benefits but Stitch Fix and ModCloth examples suggest personalization is hard even for vendors. (3) I should ask about Option 3 (hybrid) more—AI focused on Options 1 vs. 2 but hybrid might split the difference on speed vs. control."

**What makes this excellent**:
- ✅ Clear recommendation with reasoning
- ✅ Integrates multiple AI insights (opportunity costs, execution risk)
- ✅ Shows synthesis in own words (not just repeating AI)
- ✅ Acknowledges what AI helped with vs. what requires human judgment
- ✅ Identifies what to probe deeper on (shows iterative thinking)

---

## Question 4: Your Position & Decision Rationale

### Point Distribution (10 points total)
- Part A - Vote stated: 1 point (just need to state it clearly)
- Part B - Core argument: 4 points (Business Acumen 60%, Ethical Awareness 40%)
- Part C - Anticipating opposition: 3 points (Prompt Sophistication - shows critical thinking)
- Part D - Breaking news factor: 2 points (Business Acumen - dealing with uncertainty)

### Scoring Breakdown

**Business Acumen (3.5 points - 35%)**:
- Practical reasoning about decision
- Integration of financial, competitive, operational factors
- Realistic about implementation and risks

**Ethical Awareness (3.5 points - 35%)**:
- Addresses privacy/customer concerns as business factors
- Considers stakeholder impacts
- Balances ethics and business (not separate)

**Prompt Sophistication (3 points - 30%)**:
- Anticipates strong counter arguments (shows critical thinking)
- Rebuttals show depth of reasoning
- Shows uncertainty awareness (Part D)

---

### Part B: Exemplary Core Arguments (by option)

**Option 1 - Buy Full Vendor: Exceptional Argument**:

> "I'm voting for Option 1 (Buy Full Vendor) despite the privacy concerns and vendor dependency risk. Here's why: TrendSetters is in a competitive crisis. Three quarters of declining revenue, 68% of customers never returning, and email performance below industry average. The board gave management a mandate: improve customer lifetime value 20% within 18 months. Option 1 is the ONLY choice that can deliver results in that timeframe.
>
> The financial math is compelling when you include opportunity costs. Yes, vendor is $850K Year 1 vs. Option 2's $1.2M—but more importantly, we're in market with working solution in 3-4 months vs. 18-24 months. If CustomerIQ delivers even 60% of promised improvements (15% AOV increase, 12% retention), we generate $5-8M in incremental revenue during those 15 months that Option 2 is still in development. That more than pays for vendor dependency risk.
>
> On privacy: The breaking news is concerning, but it's a vendor misconfiguration, not a platform vulnerability. We can deploy CustomerIQ WITHOUT facial recognition and WITHOUT third-party data purchases—just use our own customer data for email/web personalization. This addresses 80% of privacy concerns while keeping 90% of value. And we'll negotiate contract protections: data portability, price caps, exit rights. This makes vendor dependency manageable.
>
> The alternative—building internal while competitors pull ahead—is the real risk. TrendSetters doesn't have 18 months to figure this out. We need results now."

**What makes this exceptional**:
- ✅ Leads with strongest argument (competitive urgency)
- ✅ Quantifies the case (specific revenue, timeframes)
- ✅ Addresses main objections proactively (privacy, vendor dependency)
- ✅ Proposes mitigation strategies (exclude facial recognition, contract protections)
- ✅ Integrates business + ethics (privacy as business risk, not separate concern)

**Option 2 - Build Internal: Exceptional Argument**:

> "I'm voting for Option 2 (Build Internal) because sustainable competitive advantage requires controlling critical capabilities, not outsourcing them. Brad was right in Case 1: you can't control your destiny when vendors control your differentiation.
>
> The 18-24 month timeline is painful, but consider the long view: In Year 3, Option 1 costs $1.69M total and we still don't own anything—we're paying $420K/year forever and Nexus controls our roadmap. Option 2 costs $2.56M over 3 years but we OWN the capability. By Year 5, the crossover happens: internal is cheaper AND we have proprietary IP that competitors can't buy. Given TrendSetters positions on 'conscious consumer' values, owning our personalization aligns with the brand better than relying on a VC-backed startup with aggressive data practices.
>
> Yes, execution risk is real. We might fail or take longer than 18 months. But the alternative is certainty of vendor dependency. And the breaking news proves this: what if Nexus has more privacy issues? What if they get acquired? What if they 3X our licensing fees in Year 3? Building internal is the only option that eliminates these risks entirely.
>
> On competitive timing: Our competitors who deployed vendor AI 6 months ago aren't crushing us yet. We're not in free fall. We have time to build this right. The vendors' case studies show 15% improvements—but Stitch Fix and Everlane built internal and they're category leaders. Maybe building proprietary capability is how you WIN, not just how you keep up."

**What makes this exceptional**:
- ✅ Clear strategic thesis (own critical capabilities)
- ✅ Long-term financial thinking (Year 5 crossover analysis)
- ✅ Connects to brand values and company identity
- ✅ Acknowledges execution risk but argues it's better than dependency risk
- ✅ Uses breaking news to strengthen argument (vendor risk is real)

**Option 4 - Pilot: Exceptional Argument**:

> "I'm voting for Option 4 (Pilot) because it's the lowest-risk way to learn whether AI personalization actually delivers for TrendSetters' specific customers before we commit $850K+ and bet the company on it.
>
> The vendor's case studies show 15% AOV increase and 12% retention improvement—but those are other retailers with different customer bases, different brands, different geographies. TrendSetters serves 'conscious consumers' who chose us partly because we're NOT Amazon. What if our customers react negatively to algorithmic personalization? What if the 'creep factor' of AI recommendations hurts our brand with the 45+ segment who values human service? We don't know. A $280K pilot with our most engaged 500K customers lets us TEST these assumptions before betting the company.
>
> This addresses both the 'move fast' camp and the 'control our destiny' camp. To the fast movers: 6-month pilot + 3-month expansion = 9 months total, vs. 18-24 months for internal build. We're still faster than Option 2. To the autonomy camp: pilot results inform whether to go full vendor (Option 1), build internal (Option 2), or try hybrid (Option 3). We're not locked in.
>
> The breaking news actually STRENGTHENS the pilot case. Do we really want to go all-in on CustomerIQ right now when they're under FTC investigation? Pilot lets us see if Nexus fixes their privacy issues, whether regulators impose restrictions, and whether our 'conscious consumer' customers even want this. If pilot works and privacy concerns resolve, we expand. If not, we're only out $280K vs. $850K."

**What makes this exceptional**:
- ✅ Strategic use of pilot as de-risking mechanism
- ✅ Challenges vendor case studies ("their customers aren't our customers")
- ✅ Bridges multiple positions (satisfies both speed and control concerns)
- ✅ Uses breaking news to strengthen pilot argument (test before committing)
- ✅ Specific about what pilot would teach them

---

### Part C: Exemplary Objections & Rebuttals

**Strong responses anticipate the STRONGEST arguments against their position** (not weak ones they can easily dismiss):

**If you voted Option 1 (Vendor), strong objections to address**:

**Objection 1 - Vendor Dependency**:
> "Brad's argument from Case 1 applies: once we're dependent on CustomerIQ, Nexus controls our destiny. They can raise prices, prioritize other clients, or get acquired. We'll have surrendered a critical competitive capability to a vendor we can't control."
>
> **Rebuttal**: This risk is real but manageable through contract protections (data portability, price caps, exit rights). More importantly, the alternative—waiting 18 months to build internal while competitors gain ground—is a CERTAIN loss of competitive position. Vendor dependency is a potential risk; falling behind competitors is a guaranteed outcome of Option 2's timeline. I'll take manageable risk over certain competitive decline.

**Objection 2 - Privacy Concerns After Breaking News**:
> "The CustomerIQ breach and FTC investigation shows this platform has serious privacy vulnerabilities. 'Conscious consumer' brand customers will revolt if we deploy surveillance-level data collection right after this news broke."
>
> **Rebuttal**: Valid concern, but we're not required to use the most aggressive features (facial recognition, third-party data). We can deploy email/web personalization using only OUR customer data (purchases, browsing), which customers expect and accept. This addresses 90% of privacy concerns while keeping 80% of the value. Also, Nexus will be hypersensitive to privacy now post-investigation—ironically might be SAFER to deploy post-scrutiny than pre-scrutiny.

**If you voted Option 2 (Build Internal), strong objections to address**:

**Objection 1 - Execution Risk & Timeline**:
> "Mid-market retailers who've tried internal AI builds have mostly failed or taken 2-3X longer than projected. ModCloth spent $4M over 36 months and failed. Stitch Fix succeeded but needed 50+ data scientists. TrendSetters' plan to hire 2-3 people and deliver in 18 months is fantasy."
>
> **Rebuttal**: Those examples are from 2018-2020 when ML tooling was primitive. In 2025, GPT-4, Claude, and open-source frameworks make building personalization much easier. Our team of 2-3 engineers plus modern AI tools can match what required 50 data scientists 5 years ago. Yes, it might take 24 months instead of 18—but that's still better than permanent vendor dependency. And if we DO fail, we've at least built AI capability we can apply elsewhere (product recommendations, inventory optimization).

**Objection 2 - Competitive Timing**:
> "The case shows three consecutive quarters of revenue decline. We can't afford 18-24 months. Competitors using AI will pull so far ahead that we'll never catch up. CMO's job is on the line if we don't show results fast."
>
> **Rebuttal**: The decline is serious but not free-fall. Same-store sales down 6%, not 25%. E-commerce still growing at 12%. We're not in a crisis requiring panic decisions. Also, fast-follow can be smarter than first-mover: we'll learn from competitors' mistakes, build a better system, and own the IP. Stitch Fix and Everlane didn't rush to buy vendor solutions—they invested in proprietary capability and became category leaders because of it. TrendSetters should do the same.

**What makes these strong**:
- ✅ Identifies genuinely strong objections (not strawmen)
- ✅ Rebuttals engage with the substance (not dismissive)
- ✅ Shows has thought through counterarguments
- ✅ Demonstrates intellectual humility (acknowledges concerns have merit)

---

### Part D: Breaking News Factor - Exemplary Elements

**Strong responses address uncertainty awareness**:

**If Breaking News STRENGTHENS your position**:

> "The CustomerIQ privacy breach strengthens my vote for Option 4 (Pilot). I was leaning pilot anyway for de-risking reasons, but this news confirms the wisdom of 'test before you bet the company.' If we'd chosen Option 1 and deployed full CustomerIQ last month, we'd now be associated with the FTC investigation and customer backlash. The $280K pilot lets us see whether Nexus fixes their issues, whether customers care, and whether our 'conscious consumer' brand can survive association with aggressive data collection. If the answer is yes, we expand. If no, we've protected our brand for only $280K."

**If Breaking News CHALLENGES your position**:

> "The CustomerIQ news makes my Option 1 vote harder to defend. I chose vendor for speed (3-4 months), but deploying a platform under FTC investigation feels reckless. However, I still think Option 1 is right IF we: (1) exclude the most controversial features (facial recognition, third-party data), (2) wait 2-3 months for FTC investigation to resolve before full deployment, and (3) negotiate stronger privacy protections in contract. This essentially turns Option 1 into a 'modified fast deployment'—slightly slower than original plan but still 12+ months faster than building internal. The news changes HOW we deploy Option 1, not WHETHER we should."

**If Breaking News DOESN'T CHANGE your thinking**:

> "The CustomerIQ news doesn't change my Option 2 (build internal) vote—it actually reinforces it. I was already concerned about vendor dependency and privacy risks BEFORE this news. Brad's Case 1 principle was: don't depend on external vendors to fix critical problems because you can't control their behavior. This news proves Brad right. We can't control whether Nexus has privacy breaches, how they respond, whether they get fined, or whether customers trust them. The ONLY way to fully control privacy practices and brand risk is to build and own our own system. The news just makes the case for internal build more obvious."

**What makes these strong**:
- ✅ Honest about how news affects (or doesn't affect) their position
- ✅ Shows ability to adapt to new information OR explain why position is robust
- ✅ Demonstrates decision-making under uncertainty
- ✅ Not overly rigid (can acknowledge disconfirming evidence)

---

## Common Student Mistakes to Watch For

### Prompt Quality Issues (Question 3):

**Red Flags**:
- "Which option should TrendSetters choose?" (asking AI to decide)
- "Tell me about AI in marketing" (too vague, no context)
- "Compare the five options" (no specificity about what to compare on)
- No explanation of WHY they're asking or WHAT they learned
- Accepting AI's answer without critical evaluation
- Single prompts with no iteration or follow-up

**Good Practice**:
- Prompts provide full context about the business situation
- Ask AI to help understand, not decide
- Request specific analysis (financial, risk, customer segments)
- Explain purpose and learning for each prompt
- Show critical evaluation (what did AI miss? what assumptions?)
- Evidence of iterative refinement

### Analysis Issues (Questions 1, 2, 4):

**Red Flags**:
- Generic statements that could apply to any case ("vendor solutions are risky")
- No specific case references (numbers, facts, quotes)
- Treating ethics separately from business ("first the business case, now the ethics...")
- Ignoring obvious trade-offs (pretending their option has no downsides)
- Weak opposition arguments that are easy to dismiss
- Not connecting to Case 1 learnings when explicitly asked

**Good Practice**:
- Specific case engagement (references $850K, 68% one-time buyers, 18-24 months, etc.)
- Ethics integrated as business considerations (reputation, trust, customer segments)
- Honest acknowledgment of trade-offs
- Strong opposition arguments that challenge their position
- Applies lessons from Case 1 (Brad's vendor dependency, Dee's generational insight)

---

## Grading Efficiency Tips

**Time Target**: 5-7 minutes per student (85-120 minutes for all 17 students)

**Batch Grading Strategy**:
1. Grade all Question 1's (build-vs-buy) together
2. Grade all Question 3's (prompts) together  
3. Grade all Question 4's (positions) together
4. Skip Question 2 if time-pressed (it's somewhat repetitive with Q1)

**Comment Bank** (copy/paste for efficiency):

*Prompt Quality*:
- "Strong prompt—specific context, strategic question, critical evaluation evident"
- "Prompt is too vague. Provide more context about TrendSetters' situation and what you need to understand"
- "Good start, but WHERE is your critical evaluation of AI's response? Don't just accept what it says"
- "Excellent iterative thinking—your follow-up questions show you engaged deeply with AI"

*Analysis Quality*:
- "Strong case engagement—references specific numbers and facts"
- "Generic argument. Could apply to any vendor decision. Make it specific to TrendSetters"
- "Good recognition of trade-offs. Shows you understand no perfect answer"
- "Ethics treated separately from business. Integrate: privacy IS a business risk"

*Integration*:
- "Excellent application of Case 1 learnings (Brad's principle, Dee's insight)"
- "You had opportunity to connect to Case 1—why didn't you?"
- "Strong synthesis of AI insights into your own reasoning"

**Focus Detailed Feedback** on Question 3 (prompts). That's where students need most skill development. Questions 1, 2, 4 can get briefer comments.

---

## Grade Distribution Expectations

For a well-prepared class on Case 2:
- **A range (90-100%)**: 25-35% (should increase vs. Case 1 as they learn)
- **B range (80-89%)**: 40-50%
- **C range (70-79%)**: 15-25%
- **Below 70%**: Under 10%

If distribution is much different:
- Too many high grades: Are expectations clear enough? Is rubric too lenient?
- Too many low grades: Was case too hard? Were prompt examples sufficient?
- Check if students understood the AI collaboration focus vs. trying to be finance experts

---

*Grading guide prepared for*: Case 2 - TrendSetters Retail  
*Course*: Generative AI for Business and Creative Professionals  
*Refer to*: Master Rubrics Document for detailed scoring criteria
